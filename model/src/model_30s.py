import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import h5py
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
import seaborn as sns
import platform
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')  # Windows
elif platform.system() == 'Darwin':
    plt.rc('font', family='AppleGothic')  # Mac
else:
    plt.rc('font', family='NanumGothic')  # Linux
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€


# ===== HDF5 ë°ì´í„°ì…‹ í´ëž˜ìŠ¤ =====
class HDF5CardiacDataset(Dataset):
    """HDF5 í¬ë§· ECG, PPG ë°ì´í„°ì…‹ (í‘œì¤€ êµ¬ì¡°)"""
    
    def __init__(self, hdf5_file, indices=None, load_to_memory=True):
        self.hdf5_file = hdf5_file
        self.load_to_memory = load_to_memory
        
        with h5py.File(hdf5_file, 'r') as hf:
            print(f"\nðŸ“‚ HDF5 íŒŒì¼: {Path(hdf5_file).name}")
            
            keys = list(hf.keys())
            
            # ê·¸ë£¹ êµ¬ì¡°ì¸ì§€ í™•ì¸
            if keys and isinstance(hf[keys[0]], h5py.Group):
                print(f"   âš ï¸  ê·¸ë£¹ êµ¬ì¡° ê°ì§€! HDF5GroupCardiacDatasetì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                raise ValueError("ì´ íŒŒì¼ì€ ê·¸ë£¹ êµ¬ì¡°ìž…ë‹ˆë‹¤. HDF5GroupCardiacDatasetì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            
            # ë°ì´í„°ì…‹ í‚¤ ìžë™ ê°ì§€
            if 'ecg' in hf.keys() and 'ppg' in hf.keys():
                ecg_key, ppg_key = 'ecg', 'ppg'
            elif 'ECG' in hf.keys() and 'PPG' in hf.keys():
                ecg_key, ppg_key = 'ECG', 'PPG'
            else:
                raise KeyError(f"ECG/PPG ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‚¤: {keys}")
            
            if 'n_samples' in hf.attrs:
                self.n_samples = hf.attrs['n_samples']
                self.sequence_length = hf.attrs['sequence_length']
                self.sampling_rate = hf.attrs.get('sampling_rate', 256)
            else:
                self.n_samples = hf[ecg_key].shape[0]
                self.sequence_length = hf[ecg_key].shape[1]
                self.sampling_rate = 256
            
            if indices is None:
                self.indices = list(range(self.n_samples))
            else:
                self.indices = indices
            
            if load_to_memory:
                self.ecg_data = hf[ecg_key][:].astype(np.float32)
                self.ppg_data = hf[ppg_key][:].astype(np.float32)
                print(f"   âœ… ë¡œë“œ ì™„ë£Œ: {self.n_samples}ê°œ, ê¸¸ì´={self.sequence_length}, ECG={self.ecg_data.shape}")
            else:
                self.ecg_data = None
                self.ppg_data = None
                self.ecg_key = ecg_key
                self.ppg_key = ppg_key
    
    def __len__(self):
        return len(self.indices)
    
    def __getitem__(self, idx):
        real_idx = self.indices[idx]
        
        if self.load_to_memory:
            ecg = self.ecg_data[real_idx]
            ppg = self.ppg_data[real_idx]
        else:
            with h5py.File(self.hdf5_file, 'r') as hf:
                ecg_key = getattr(self, 'ecg_key', 'ecg')
                ppg_key = getattr(self, 'ppg_key', 'ppg')
                ecg = hf[ecg_key][real_idx]
                ppg = hf[ppg_key][real_idx]
        
        sample = np.stack([ecg, ppg], axis=0)
        sample = torch.FloatTensor(sample)
        
        return sample, sample


class HDF5GroupCardiacDataset(Dataset):
    """ê·¸ë£¹ êµ¬ì¡°ì˜ HDF5 í¬ë§· ECG, PPG ë°ì´í„°ì…‹"""
    
    def __init__(self, hdf5_file, indices=None, load_to_memory=True):
        self.hdf5_file = hdf5_file
        self.load_to_memory = load_to_memory
        
        with h5py.File(hdf5_file, 'r') as hf:
            print(f"\nðŸ“‚ ê·¸ë£¹ êµ¬ì¡° HDF5: {Path(hdf5_file).name}")
            
            self.group_names = sorted([key for key in hf.keys() if isinstance(hf[key], h5py.Group)])
            self.n_samples = len(self.group_names)
            
            if self.n_samples > 0:
                first_group = hf[self.group_names[0]]
                self.sequence_length = first_group['ecg'].shape[0]
                self.sampling_rate = 256
            else:
                raise ValueError("ê·¸ë£¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            if indices is None:
                self.indices = list(range(self.n_samples))
            else:
                self.indices = indices
            
            if load_to_memory:
                ecg_list = []
                ppg_list = []
                
                for group_name in self.group_names:
                    group = hf[group_name]
                    ecg = group['ecg'][:].astype(np.float32)
                    ppg = group['ppg'][:].astype(np.float32)
                    ecg_list.append(ecg)
                    ppg_list.append(ppg)
                
                self.ecg_data = np.array(ecg_list, dtype=np.float32)
                self.ppg_data = np.array(ppg_list, dtype=np.float32)
                print(f"   âœ… ë¡œë“œ ì™„ë£Œ: {self.n_samples}ê°œ, ê¸¸ì´={self.sequence_length}")
            else:
                self.ecg_data = None
                self.ppg_data = None
    
    def __len__(self):
        return len(self.indices)
    
    def __getitem__(self, idx):
        real_idx = self.indices[idx]
        
        if self.load_to_memory:
            ecg = self.ecg_data[real_idx]
            ppg = self.ppg_data[real_idx]
        else:
            with h5py.File(self.hdf5_file, 'r') as hf:
                group_name = self.group_names[real_idx]
                ecg = hf[group_name]['ecg'][:].astype(np.float32)
                ppg = hf[group_name]['ppg'][:].astype(np.float32)
        
        sample = np.stack([ecg, ppg], axis=0)
        sample = torch.FloatTensor(sample)
        
        return sample, sample


def load_dataset_auto(hdf5_file, indices=None, load_to_memory=True):
    """HDF5 êµ¬ì¡°ë¥¼ ìžë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì ì ˆí•œ Dataset ë°˜í™˜"""
    with h5py.File(hdf5_file, 'r') as hf:
        keys = list(hf.keys())
        
        if keys and isinstance(hf[keys[0]], h5py.Group):
            return HDF5GroupCardiacDataset(hdf5_file, indices, load_to_memory)
        else:
            return HDF5CardiacDataset(hdf5_file, indices, load_to_memory)


def create_train_val_test_datasets(hdf5_file, train_ratio=0.75, val_ratio=0.15, load_to_memory=True):
    """í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì‚¼ë¶„í•  (7.5:1.5:1)"""
    with h5py.File(hdf5_file, 'r') as hf:
        if 'ecg' in hf.keys():
            ecg_key = 'ecg'
        elif 'ECG' in hf.keys():
            ecg_key = 'ECG'
        else:
            keys = list(hf.keys())
            if keys and isinstance(hf[keys[0]], h5py.Group):
                n_samples = len([k for k in keys if isinstance(hf[k], h5py.Group)])
            else:
                raise KeyError(f"ECG ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‚¤: {list(hf.keys())}")
        
        if 'n_samples' in hf.attrs:
            n_samples = hf.attrs['n_samples']
        else:
            if 'ecg_key' in locals():
                n_samples = hf[ecg_key].shape[0]
    
    indices = np.arange(n_samples)
    np.random.seed(42)
    np.random.shuffle(indices)
    
    train_end = int(n_samples * train_ratio)
    val_end = train_end + int(n_samples * val_ratio)
    
    train_indices = indices[:train_end].tolist()
    val_indices = indices[train_end:val_end].tolist()
    test_indices = indices[val_end:].tolist()
    
    print(f"\nðŸ“Š ë°ì´í„° ë¶„í•  (ì´ {n_samples}ê°œ)")
    print(f"   Train: {len(train_indices)}ê°œ ({len(train_indices)/n_samples*100:.1f}%)")
    print(f"   Val:   {len(val_indices)}ê°œ ({len(val_indices)/n_samples*100:.1f}%)")
    print(f"   Test:  {len(test_indices)}ê°œ ({len(test_indices)/n_samples*100:.1f}%)")
    
    train_dataset = load_dataset_auto(hdf5_file, indices=train_indices, load_to_memory=load_to_memory)
    val_dataset = load_dataset_auto(hdf5_file, indices=val_indices, load_to_memory=load_to_memory)
    test_dataset = load_dataset_auto(hdf5_file, indices=test_indices, load_to_memory=load_to_memory)
    
    return train_dataset, val_dataset, test_dataset


# ===== CNN-GRU ì˜¤í† ì¸ì½”ë” ëª¨ë¸ (30ì´ˆìš©) =====
class CNNGRUAutoencoder30s(nn.Module):
    """CNN-GRU ê¸°ë°˜ ì˜¤í† ì¸ì½”ë” (30ì´ˆ = 7680 samples)"""
    
    def __init__(self, input_channels=2, sequence_length=7680, latent_dim=128):
        super(CNNGRUAutoencoder30s, self).__init__()
        
        self.input_channels = input_channels
        self.sequence_length = sequence_length
        self.latent_dim = latent_dim
        
        # Encoder CNN: 7680 â†’ 120
        self.encoder_cnn = nn.Sequential(
            nn.Conv1d(input_channels, 32, kernel_size=7, stride=4, padding=3),  # 7680 â†’ 1920
            nn.BatchNorm1d(32),
            nn.ReLU(),
            
            nn.Conv1d(32, 64, kernel_size=5, stride=4, padding=2),  # 1920 â†’ 480
            nn.BatchNorm1d(64),
            nn.ReLU(),
            
            nn.Conv1d(64, 128, kernel_size=5, stride=4, padding=2),  # 480 â†’ 120
            nn.BatchNorm1d(128),
            nn.ReLU(),
        )
        
        self.encoder_gru = nn.GRU(
            input_size=128,
            hidden_size=128,
            num_layers=2,
            batch_first=True,
            dropout=0.2,
            bidirectional=True
        )
        
        self.encoder_fc = nn.Linear(128 * 2, latent_dim)
        
        # Decoder
        self.decoder_fc = nn.Linear(latent_dim, 128 * 120)
        
        self.decoder_gru = nn.GRU(
            input_size=128,
            hidden_size=128,
            num_layers=2,
            batch_first=True,
            dropout=0.2,
            bidirectional=False
        )
        
        # Decoder CNN: 120 â†’ 7680
        self.decoder_cnn = nn.Sequential(
            nn.ConvTranspose1d(128, 64, kernel_size=5, stride=4, padding=2, output_padding=3),  # 120 â†’ 480
            nn.BatchNorm1d(64),
            nn.ReLU(),
            
            nn.ConvTranspose1d(64, 32, kernel_size=5, stride=4, padding=2, output_padding=3),  # 480 â†’ 1920
            nn.BatchNorm1d(32),
            nn.ReLU(),
            
            nn.ConvTranspose1d(32, input_channels, kernel_size=7, stride=4, padding=3, output_padding=3),  # 1920 â†’ 7680
        )
    
    def encode(self, x):
        x = self.encoder_cnn(x)
        x = x.permute(0, 2, 1)
        _, hidden = self.encoder_gru(x)
        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)
        z = self.encoder_fc(hidden)
        return z
    
    def decode(self, z):
        batch_size = z.size(0)
        x = self.decoder_fc(z)
        x = x.view(batch_size, 120, 128)
        x, _ = self.decoder_gru(x)
        x = x.permute(0, 2, 1)
        x = self.decoder_cnn(x)
        return x
    
    def forward(self, x):
        z = self.encode(x)
        reconstructed = self.decode(z)
        return reconstructed, z


# ===== ì˜ë£Œê¸°ê¸° ì„±ëŠ¥ í‰ê°€ í´ëž˜ìŠ¤ =====
class MedicalDevicePerformanceEvaluator:
    """ì‹ì•½ì²˜ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ì˜ë£Œê¸°ê¸° ì„±ëŠ¥ í‰ê°€"""
    
    def __init__(self, model, threshold_percentile=95):
        self.model = model
        self.threshold_percentile = threshold_percentile
        self.threshold = None
        self.reconstruction_errors = []
    
    def calculate_reconstruction_error(self, original, reconstructed):
        mse = torch.mean((original - reconstructed) ** 2, dim=(1, 2))
        return mse
    
    def fit_threshold(self, dataloader, device='cpu'):
        self.model.eval()
        errors = []
        
        print(f"ì •ìƒ ë°ì´í„°ë¡œ ìž„ê³„ê°’ ì„¤ì • ì¤‘...")
        with torch.no_grad():
            for data, _ in dataloader:
                data = data.to(device)
                reconstructed, _ = self.model(data)
                error = self.calculate_reconstruction_error(data, reconstructed)
                errors.extend(error.cpu().numpy())
                
                del data, reconstructed, error
                if device.type == 'cuda':
                    torch.cuda.empty_cache()
        
        self.reconstruction_errors = errors
        self.threshold = np.percentile(errors, self.threshold_percentile)
        print(f"âœ… ì´ìƒ íƒì§€ ìž„ê³„ê°’: {self.threshold:.6f} ({self.threshold_percentile}th percentile)")
        print(f"   ì •ìƒ ë°ì´í„° ì˜¤ì°¨ ë²”ìœ„: [{np.min(errors):.6f}, {np.max(errors):.6f}]")
        print(f"   ì •ìƒ ë°ì´í„° í‰ê·  ì˜¤ì°¨: {np.mean(errors):.6f}")
        
        return self.threshold
    
    def evaluate_dataset(self, dataloader, true_label, dataset_name, device='cpu'):
        self.model.eval()
        all_errors = []
        
        print(f"\nðŸ“Š {dataset_name} ë°ì´í„° í‰ê°€ ì¤‘...")
        with torch.no_grad():
            for data, _ in dataloader:
                data = data.to(device)
                reconstructed, _ = self.model(data)
                error = self.calculate_reconstruction_error(data, reconstructed)
                
                all_errors.extend(error.cpu().numpy())
                
                del data, reconstructed, error
                if device.type == 'cuda':
                    torch.cuda.empty_cache()
        
        all_errors = np.array(all_errors)
        predictions = (all_errors > self.threshold).astype(int)
        true_labels = np.full(len(all_errors), true_label)
        
        print(f"âœ… {dataset_name} í‰ê°€ ì™„ë£Œ: {len(all_errors)}ê°œ")
        print(f"   ì˜¤ì°¨ ë²”ìœ„: [{np.min(all_errors):.6f}, {np.max(all_errors):.6f}]")
        print(f"   í‰ê·  ì˜¤ì°¨: {np.mean(all_errors):.6f}")
        print(f"   ì´ìƒ ì˜ˆì¸¡: {np.sum(predictions)}ê°œ ({np.sum(predictions)/len(predictions)*100:.2f}%)")
        
        return all_errors, true_labels, predictions
    
    def calculate_medical_metrics(self, y_true, y_pred, scores):
        cm = confusion_matrix(y_true, y_pred)
        
        if cm.shape == (2, 2):
            tn, fp, fn, tp = cm.ravel()
        elif cm.shape == (1, 1):
            if y_true[0] == 0:
                tn = cm[0, 0]
                fp, fn, tp = 0, 0, 0
            else:
                tp = cm[0, 0]
                tn, fp, fn = 0, 0, 0
        else:
            raise ValueError(f"Unexpected confusion matrix: {cm.shape}")
        
        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0
        npv = tn / (tn + fn) if (tn + fn) > 0 else 0
        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
        f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0
        
        try:
            fpr, tpr, _ = roc_curve(y_true, scores)
            roc_auc = auc(fpr, tpr)
        except:
            fpr, tpr = [0, 1], [0, 1]
            roc_auc = 0.5
        
        try:
            precision, recall, _ = precision_recall_curve(y_true, scores)
            pr_auc = auc(recall, precision)
        except:
            precision, recall = [1, 0], [0, 1]
            pr_auc = 0.5
        
        return {
            'TP': int(tp), 'TN': int(tn), 'FP': int(fp), 'FN': int(fn),
            'Sensitivity': sensitivity, 'Specificity': specificity,
            'PPV': ppv, 'NPV': npv, 'Accuracy': accuracy, 'F1_Score': f1_score,
            'ROC_AUC': roc_auc, 'PR_AUC': pr_auc, 'Threshold': self.threshold,
            'FPR': fpr, 'TPR': tpr,
            'Precision_curve': precision, 'Recall_curve': recall
        }


import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import h5py
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
import seaborn as sns
import platform
warnings.filterwarnings('ignore')

# (ì´ íŒŒì¼ì˜ ë‹¤ë¥¸ í•¨ìˆ˜ë“¤ì€ ìƒëžµ... HDF5CardiacDataset, CNNGRUAutoencoder30s ë“±...)
# (ì•„ëž˜ëŠ” ìˆ˜ì •ëœ ì‹œê°í™” í•¨ìˆ˜ìž…ë‹ˆë‹¤)

# ===== ì„±ëŠ¥ ì‹œê°í™” (ë™ì¼) =====
def plot_medical_performance_dashboard(metrics, normal_errors, abnormal_errors, save_path=None):
    """ì‹ì•½ì²˜ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ"""
    
    # 1. --- ì „ì²´ ëŒ€ì‹œë³´ë“œ ê·¸ë¦¬ê¸° (Figure 1) ---
    fig = plt.figure(figsize=(20, 14))
    gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.3)
    
    # 1. Confusion Matrix
    ax1 = fig.add_subplot(gs[0, 0])
    cm = np.array([[metrics['TN'], metrics['FP']], [metrics['FN'], metrics['TP']]])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1, 
                xticklabels=['ì •ìƒ(Pred)', 'ì´ìƒ(Pred)'],
                yticklabels=['ì •ìƒ(True)', 'ì´ìƒ(True)'],
                cbar_kws={'label': 'ìƒ˜í”Œ ìˆ˜'}, annot_kws={'size': 14, 'weight': 'bold'})
    ax1.set_title('Confusion Matrix', fontsize=14, fontweight='bold', pad=10)
    
    # 2. ì„±ëŠ¥ ì§€í‘œ
    ax2 = fig.add_subplot(gs[0, 1])
    metrics_names = ['ë¯¼ê°ë„\n(Sensitivity)', 'íŠ¹ì´ë„\n(Specificity)', 'PPV', 'NPV', 'ì •í™•ë„\n(Accuracy)', 'F1']
    metrics_values = [metrics['Sensitivity'], metrics['Specificity'], 
                      metrics['PPV'], metrics['NPV'], metrics['Accuracy'], metrics['F1_Score']]
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F']
    bars = ax2.barh(metrics_names, metrics_values, color=colors, edgecolor='black', linewidth=1.5)
    ax2.set_xlim([0, 1.0])
    ax2.set_xlabel('Score', fontsize=12)
    ax2.set_title('ì‹ì•½ì²˜ ê°€ì´ë“œë¼ì¸ ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ', fontsize=14, fontweight='bold')
    ax2.grid(axis='x', alpha=0.3)
    ax2.axvline(x=0.95, color='red', linestyle='--', linewidth=2, alpha=0.5, label='ëª©í‘œ: 95%')
    ax2.legend(fontsize=10)
    
    for i, (bar, value) in enumerate(zip(bars, metrics_values)):
        color = 'green' if value >= 0.95 else 'red' if value < 0.85 else 'orange'
        ax2.text(value + 0.02, i, f'{value:.3f}', va='center', fontsize=11, fontweight='bold', color=color)
    
    # 3. ROC Curve
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.plot(metrics['FPR'], metrics['TPR'], color='#E74C3C', linewidth=2.5, 
             label=f'ROC (AUC = {metrics["ROC_AUC"]:.3f})')
    ax3.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random')
    ax3.fill_between(metrics['FPR'], metrics['TPR'], alpha=0.3, color='#E74C3C')
    ax3.set_xlabel('False Positive Rate', fontsize=12)
    ax3.set_ylabel('True Positive Rate', fontsize=12)
    ax3.set_title('ROC Curve', fontsize=14, fontweight='bold')
    ax3.legend(loc='lower right')
    ax3.grid(True, alpha=0.3)
    
    # 4. PR Curve
    ax4 = fig.add_subplot(gs[1, 0])
    ax4.plot(metrics['Recall_curve'], metrics['Precision_curve'], 
             color='#9B59B6', linewidth=2.5, label=f'PR (AUC = {metrics["PR_AUC"]:.3f})')
    ax4.fill_between(metrics['Recall_curve'], metrics['Precision_curve'], alpha=0.3, color='#9B59B6')
    ax4.set_xlabel('Recall', fontsize=12)
    ax4.set_ylabel('Precision', fontsize=12)
    ax4.set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')
    ax4.legend(loc='upper right')
    ax4.grid(True, alpha=0.3)
    
    # 5. ìž¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬
    ax5 = fig.add_subplot(gs[1, 1:])
    ax5.hist(normal_errors, bins=50, alpha=0.6, color='#3498DB', edgecolor='black',
             label=f'ì •ìƒ (n={len(normal_errors)})', density=True)
    ax5.hist(abnormal_errors, bins=50, alpha=0.6, color='#E74C3C', edgecolor='black',
             label=f'ë¹„ì •ìƒ (n={len(abnormal_errors)})', density=True)
    ax5.axvline(metrics['Threshold'], color='green', linestyle='--', linewidth=3,
                label=f"ìž„ê³„ê°’ = {metrics['Threshold']:.6f}")
    ax5.set_xlabel('ìž¬êµ¬ì„± ì˜¤ì°¨ (MSE)', fontsize=12)
    ax5.set_ylabel('ë°€ë„', fontsize=12)
    ax5.set_title('ì •ìƒ vs ë¹„ì •ìƒ ìž¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬', fontsize=14, fontweight='bold')
    ax5.legend(fontsize=11)
    ax5.grid(True, alpha=0.3, axis='y')
    
    # 6. ì„±ëŠ¥ ì§€í‘œ í…Œì´ë¸”
    ax6 = fig.add_subplot(gs[2, :])
    ax6.axis('off')
    
    table_data = [
        ['ì§€í‘œ', 'ê°’', 'ì„¤ëª…'],
        ['ë¯¼ê°ë„ (Sensitivity)', f'{metrics["Sensitivity"]:.4f}', 'ì‹¤ì œ ì´ìƒ ì¤‘ ì–‘ì„± íŒì • ë¹„ìœ¨'],
        ['íŠ¹ì´ë„ (Specificity)', f'{metrics["Specificity"]:.4f}', 'ì‹¤ì œ ì •ìƒ ì¤‘ ìŒì„± íŒì • ë¹„ìœ¨'],
        ['ì–‘ì„± ì˜ˆì¸¡ë„ (PPV)', f'{metrics["PPV"]:.4f}', 'ì–‘ì„± íŒì • ì¤‘ ì‹¤ì œ ì´ìƒ ë¹„ìœ¨'],
        ['ìŒì„± ì˜ˆì¸¡ë„ (NPV)', f'{metrics["NPV"]:.4f}', 'ìŒì„± íŒì • ì¤‘ ì‹¤ì œ ì •ìƒ ë¹„ìœ¨'],
        ['ì •í™•ë„ (Accuracy)', f'{metrics["Accuracy"]:.4f}', 'ì „ì²´ ì¤‘ ì˜¬ë°”ë¥¸ íŒì • ë¹„ìœ¨'],
        ['F1 Score', f'{metrics["F1_Score"]:.4f}', 'Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· '],
        ['ROC AUC', f'{metrics["ROC_AUC"]:.4f}', 'ROC ê³¡ì„  ì•„ëž˜ ë©´ì '],
        ['PR AUC', f'{metrics["PR_AUC"]:.4f}', 'PR ê³¡ì„  ì•„ëž˜ ë©´ì '],
    ]
    
    table = ax6.table(cellText=table_data, cellLoc='left', loc='center', colWidths=[0.25, 0.15, 0.6])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2.5)
    
    for i in range(3):
        table[(0, i)].set_facecolor('#34495E')
        table[(0, i)].set_text_props(weight='bold', color='white', fontsize=11)
    
    for i in range(1, len(table_data)):
        for j in range(3):
            table[(i, j)].set_facecolor('#ECF0F1' if i % 2 == 0 else 'white')
            table[(i, j)].set_edgecolor('black')
    
    ax6.set_title('ì˜ë£Œê¸°ê¸° ì„±ëŠ¥ ì§€í‘œ ìƒì„¸', fontsize=14, fontweight='bold', pad=20)
    
    # 7. ì¢…í•© í‰ê°€
    ax7 = fig.add_subplot(gs[3, :])
    ax7.axis('off')
    
    cohen_d = (np.mean(abnormal_errors) - np.mean(normal_errors)) / np.sqrt((np.std(normal_errors)**2 + np.std(abnormal_errors)**2) / 2)
    
    summary_text = f"""
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ðŸ“Š ì‹ì•½ì²˜ ì²´ì™¸ì§„ë‹¨ì˜ë£Œê¸°ê¸° ì„±ëŠ¥ í‰ê°€ ìš”ì•½ (30ì´ˆ ëª¨ë¸)
    
    [Confusion Matrix]  TP: {metrics['TP']:5d}  |  TN: {metrics['TN']:5d}  |  FP: {metrics['FP']:5d}  |  FN: {metrics['FN']:5d}
    
    [ì„±ëŠ¥ ì§€í‘œ]  ë¯¼ê°ë„: {metrics['Sensitivity']*100:.2f}%  |  íŠ¹ì´ë„: {metrics['Specificity']*100:.2f}%  |  ì •í™•ë„: {metrics['Accuracy']*100:.2f}%
    
    [ìž¬êµ¬ì„± ì˜¤ì°¨]  ì •ìƒ í‰ê· : {np.mean(normal_errors):.6f}  |  ë¹„ì •ìƒ í‰ê· : {np.mean(abnormal_errors):.6f}
    
    [ë¶„ë¦¬ë„]  Cohen's d = {cohen_d:.3f}  (íš¨ê³¼í¬ê¸°: {'Large' if abs(cohen_d) > 0.8 else 'Medium' if abs(cohen_d) > 0.5 else 'Small'})
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    
    ax7.text(0.5, 0.5, summary_text, transform=ax7.transAxes, fontsize=10,
             verticalalignment='center', horizontalalignment='center',
             fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    plt.suptitle('ì‹¬ìž¥ ì´ìƒì§•í›„ íƒì§€ (30ì´ˆ) - ì‹ì•½ì²˜ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€', fontsize=16, fontweight='bold', y=0.995)

    
    # 2. --- [ìˆ˜ì •ë¨] ê°œë³„ ì°¨íŠ¸ ì €ìž¥ ë° íŒì—… (Figure 2~6) ---
    
    # ê³µí†µ í—¬í¼ í•¨ìˆ˜ ì •ì˜
    def save_current_figure(directory, stem, name):
        if directory:
            try:
                filepath = directory / f"{stem}_{name}.png"
                plt.gcf().savefig(filepath, dpi=300, bbox_inches='tight')
                print(f"   âœ… {filepath.name} ì €ìž¥ ì™„ë£Œ")
            except Exception as e:
                print(f"   âš ï¸  {name}.png ì €ìž¥ ì‹¤íŒ¨: {e}")

    # ì €ìž¥ ê²½ë¡œ ì„¤ì •
    if save_path:
        p = Path(save_path)
        directory = p.parent
        stem = p.stem # ì˜ˆ: 'medical_performance_dashboard_30s'
        directory.mkdir(parents=True, exist_ok=True)
        print(f"--- ðŸ“ ê°œë³„ ì°¨íŠ¸ ì €ìž¥ ìœ„ì¹˜: {directory} ---")
    else:
        directory = None
        stem = None

    # --- 1. Confusion Matrix (ìƒˆ ìœˆë„ìš°, Figure 2) ---
    plt.figure(figsize=(8, 6))
    cm_data = np.array([[metrics['TN'], metrics['FP']], [metrics['FN'], metrics['TP']]])
    ax_cm_new = sns.heatmap(cm_data, annot=True, fmt='d', cmap='Blues', 
                            xticklabels=['ì •ìƒ(Pred)', 'ì´ìƒ(Pred)'],
                            yticklabels=['ì •ìƒ(True)', 'ì´ìƒ(True)'],
                            cbar_kws={'label': 'ìƒ˜í”Œ ìˆ˜'}, annot_kws={'size': 14, 'weight': 'bold'})
    ax_cm_new.set_title('Confusion Matrix (30s, ê°œë³„ ìœˆë„ìš°)', fontsize=14, fontweight='bold', pad=10)
    save_current_figure(directory, stem, "1_ConfusionMatrix")

    # --- 2. ì„±ëŠ¥ ì§€í‘œ (ìƒˆ ìœˆë„ìš°, Figure 3) ---
    plt.figure(figsize=(10, 7))
    metrics_names_popup = ['ë¯¼ê°ë„\n(Sensitivity)', 'íŠ¹ì´ë„\n(Specificity)', 'PPV', 'NPV', 'ì •í™•ë„\n(Accuracy)', 'F1']
    metrics_values_popup = [metrics['Sensitivity'], metrics['Specificity'], 
                            metrics['PPV'], metrics['NPV'], metrics['Accuracy'], metrics['F1_Score']]
    colors_popup = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F']
    ax_metrics_new = plt.barh(metrics_names_popup, metrics_values_popup, color=colors_popup, edgecolor='black', linewidth=1.5)
    plt.xlim([0, 1.0])
    plt.xlabel('Score', fontsize=12)
    plt.title('ì‹ì•½ì²˜ ê°€ì´ë“œë¼ì¸ ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ (30s, ê°œë³„ ìœˆë„ìš°)', fontsize=14, fontweight='bold')
    plt.grid(axis='x', alpha=0.3)
    plt.axvline(x=0.95, color='red', linestyle='--', linewidth=2, alpha=0.5, label='ëª©í‘œ: 95%')
    plt.legend(fontsize=10)
    for i, (bar, value) in enumerate(zip(ax_metrics_new, metrics_values_popup)):
        color = 'green' if value >= 0.95 else 'red' if value < 0.85 else 'orange'
        plt.text(value + 0.02, i, f'{value:.3f}', va='center', fontsize=11, fontweight='bold', color=color)
    save_current_figure(directory, stem, "2_PerformanceMetrics")

    # --- 3. ROC Curve (ìƒˆ ìœˆë„ìš°, Figure 4) ---
    plt.figure(figsize=(8, 6))
    plt.plot(metrics['FPR'], metrics['TPR'], color='#E74C3C', linewidth=2.5, 
             label=f'ROC (AUC = {metrics["ROC_AUC"]:.3f})')
    plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random')
    plt.fill_between(metrics['FPR'], metrics['TPR'], alpha=0.3, color='#E74C3C')
    plt.xlabel('False Positive Rate', fontsize=12)
    plt.ylabel('True Positive Rate', fontsize=12)
    plt.title('ROC Curve (30s, ê°œë³„ ìœˆë„ìš°)', fontsize=14, fontweight='bold')
    plt.legend(loc='lower right')
    plt.grid(True, alpha=0.3)
    save_current_figure(directory, stem, "3_ROCCurve")

    # --- 4. PR Curve (ìƒˆ ìœˆë„ìš°, Figure 5) ---
    plt.figure(figsize=(8, 6))
    plt.plot(metrics['Recall_curve'], metrics['Precision_curve'], 
             color='#9B59B6', linewidth=2.5, label=f'PR (AUC = {metrics["PR_AUC"]:.3f})')
    plt.fill_between(metrics['Recall_curve'], metrics['Precision_curve'], alpha=0.3, color='#9B59B6')
    plt.xlabel('Recall', fontsize=12)
    plt.ylabel('Precision', fontsize=12)
    plt.title('Precision-Recall Curve (30s, ê°œë³„ ìœˆë„ìš°)', fontsize=14, fontweight='bold')
    plt.legend(loc='upper right')
    plt.grid(True, alpha=0.3)
    save_current_figure(directory, stem, "4_PRCurve")

    # --- 5. ìž¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬ (ìƒˆ ìœˆë„ìš°, Figure 6) ---
    plt.figure(figsize=(10, 6))
    plt.hist(normal_errors, bins=50, alpha=0.6, color='#3498DB', edgecolor='black',
             label=f'ì •ìƒ (n={len(normal_errors)})', density=True)
    plt.hist(abnormal_errors, bins=50, alpha=0.6, color='#E74C3C', edgecolor='black',
             label=f'ë¹„ì •ìƒ (n={len(abnormal_errors)})', density=True)
    plt.axvline(metrics['Threshold'], color='green', linestyle='--', linewidth=3,
                label=f"ìž„ê³„ê°’ = {metrics['Threshold']:.6f}")
    plt.xlabel('ìž¬êµ¬ì„± ì˜¤ì°¨ (MSE)', fontsize=12)
    plt.ylabel('ë°€ë„', fontsize=12)
    plt.title('ì •ìƒ vs ë¹„ì •ìƒ ìž¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬ (30s, ê°œë³„ ìœˆë„ìš°)', fontsize=14, fontweight='bold')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3, axis='y')
    save_current_figure(directory, stem, "5_ErrorDistribution")
    
    # --- 3. [ìˆ˜ì •ë¨] ì „ì²´ ëŒ€ì‹œë³´ë“œ ì €ìž¥ ---
    if directory:
        try:
            # ì „ì²´ ëŒ€ì‹œë³´ë“œ(Figure 1) ì €ìž¥
            fig.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"--- âœ… (ì „ì²´) {p.name} ì €ìž¥ ì™„ë£Œ ---")
        except Exception as e:
            print(f"--- âš ï¸ (ì „ì²´) {p.name} ì €ìž¥ ì‹¤íŒ¨: {e} ---")

    # --- 4. ëª¨ë“  ìœˆë„ìš° ë„ìš°ê¸° ---
    plt.show()



def print_performance_report(metrics):
    """ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸"""
    print("\n" + "="*80)
    print("ðŸ“‹ ì‹ì•½ì²˜ ì²´ì™¸ì§„ë‹¨ì˜ë£Œê¸°ê¸° ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸ (30ì´ˆ ëª¨ë¸)")
    print("="*80)
    print(f"\n[Confusion Matrix]")
    print(f"  TP: {metrics['TP']:5d}  |  TN: {metrics['TN']:5d}  |  FP: {metrics['FP']:5d}  |  FN: {metrics['FN']:5d}")
    print(f"\n[ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ]")
    print(f"  ë¯¼ê°ë„: {metrics['Sensitivity']:.4f} ({metrics['Sensitivity']*100:.2f}%)")
    print(f"  íŠ¹ì´ë„: {metrics['Specificity']:.4f} ({metrics['Specificity']*100:.2f}%)")
    print(f"  PPV:    {metrics['PPV']:.4f} ({metrics['PPV']*100:.2f}%)")
    print(f"  NPV:    {metrics['NPV']:.4f} ({metrics['NPV']*100:.2f}%)")
    print(f"  ì •í™•ë„: {metrics['Accuracy']:.4f} ({metrics['Accuracy']*100:.2f}%)")
    print(f"  F1:     {metrics['F1_Score']:.4f}")
    print(f"\n[AUC]")
    print(f"  ROC: {metrics['ROC_AUC']:.4f}  |  PR: {metrics['PR_AUC']:.4f}")
    print("="*80 + "\n")


def train_autoencoder(model, train_loader, val_loader, epochs=100, lr=0.001, device='cpu', model_save_path='best_model.pth'):
    """ì˜¤í† ì¸ì½”ë” í•™ìŠµ"""
    from tqdm import tqdm
    
    Path(model_save_path).parent.mkdir(parents=True, exist_ok=True)
    
    model = model.to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)
    
    best_val_loss = float('inf')
    
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        
        for data, target in tqdm(train_loader, desc=f'[Epoch {epoch+1}/{epochs}] Training'):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            reconstructed, _ = model(data)
            loss = criterion(reconstructed, target)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            del data, target, reconstructed, loss
            if device.type == 'cuda':
                torch.cuda.empty_cache()
        
        train_loss /= len(train_loader)
        
        model.eval()
        val_loss = 0
        
        with torch.no_grad():
            for data, target in tqdm(val_loader, desc=f'[Epoch {epoch+1}/{epochs}] Validation'):
                data, target = data.to(device), target.to(device)
                reconstructed, _ = model(data)
                loss = criterion(reconstructed, target)
                val_loss += loss.item()
                del data, target, reconstructed, loss
                if device.type == 'cuda':
                    torch.cuda.empty_cache()
        
        val_loss /= len(val_loader)
        scheduler.step(val_loss)
        
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), model_save_path)
            print(f'Epoch [{epoch+1}/{epochs}], Train: {train_loss:.6f}, Val: {val_loss:.6f} â­')
        else:
            print(f'Epoch [{epoch+1}/{epochs}], Train: {train_loss:.6f}, Val: {val_loss:.6f}')


# ===== ë©”ì¸ =====
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ (ì‚¬ìš©ìžê°€ ìˆ˜ì •)
    NORMAL_HDF5_FILE = r'C:\Users\jerom\Downloads\model\dataset_30s.h5'
    ABNORMAL_HDF5_FILE = r'C:\Users\jerom\Downloads\model\30sec_test_data.h5'
    MODEL_SAVE_PATH = r'C:\Users\jerom\Downloads\model\30sec\model_test.pth'
    OUTPUT_DIR = r'C:\Users\jerom\Downloads\model\performance\30sec'
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    BATCH_SIZE = 64  # 30ì´ˆëŠ” ë°ì´í„°ê°€ í¬ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ê°ì†Œ
    EVAL_BATCH_SIZE = 32
    EPOCHS = 100
    LEARNING_RATE = 0.001
    LATENT_DIM = 128
    LOAD_TO_MEMORY = True
    THRESHOLD_PERCENTILE = 95
    
    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨
    TRAIN_RATIO = 0.75
    VAL_RATIO = 0.15
    TEST_RATIO = 0.10
    
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print("="*80)
    print("ðŸ¥ ì‹¬ìž¥ ì´ìƒì§•í›„ íƒì§€ (30ì´ˆ) - ì‹ì•½ì²˜ ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€")
    print("="*80)
    print(f"ðŸ“ ì •ìƒ ë°ì´í„°: {NORMAL_HDF5_FILE}")
    print(f"ðŸ“ ë¹„ì •ìƒ ë°ì´í„°: {ABNORMAL_HDF5_FILE}")
    print(f"ðŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {DEVICE}")
    print("="*80)
    
    # íŒŒì¼ ì¡´ìž¬ í™•ì¸
    if not Path(ABNORMAL_HDF5_FILE).exists():
        print(f"\nâŒ ë¹„ì •ìƒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ABNORMAL_HDF5_FILE}")
        exit(1)
    
    # í•™ìŠµ
    print("\n[1ë‹¨ê³„] ëª¨ë¸ ì¤€ë¹„")
    print("-" * 80)
    
    train_dataset, val_dataset, test_dataset = create_train_val_test_datasets(
        NORMAL_HDF5_FILE, train_ratio=0.75, val_ratio=0.15, load_to_memory=LOAD_TO_MEMORY
    )
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, num_workers=0)
    
    model = CNNGRUAutoencoder30s(input_channels=2, sequence_length=7680, latent_dim=LATENT_DIM)
    
    if Path(MODEL_SAVE_PATH).exists():
        print(f"âœ… ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ: {MODEL_SAVE_PATH}")
        model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))
        model = model.to(DEVICE)
    else:
        print(f"âš ï¸  ê¸°ì¡´ ëª¨ë¸ ì—†ìŒ. ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤...")
        model = model.to(DEVICE)
        train_autoencoder(model, train_loader, val_loader, EPOCHS, LEARNING_RATE, DEVICE, MODEL_SAVE_PATH)
    
    # ì„±ëŠ¥ í‰ê°€
    print("\n[2ë‹¨ê³„] ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ ì‚¬ìš©)")
    print("-" * 80)
    print("âš ï¸  ì£¼ì˜: í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ í‰ê°€í•©ë‹ˆë‹¤!")
    
    evaluator = MedicalDevicePerformanceEvaluator(model, THRESHOLD_PERCENTILE)
    
    print("\nðŸŽ¯ í•™ìŠµ ë°ì´í„°ë¡œ ìž„ê³„ê°’ ì„¤ì •")
    evaluator.fit_threshold(train_loader, device=DEVICE)
    
    print("\nðŸ“Š ì •ìƒ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€")
    normal_errors, normal_labels, normal_preds = evaluator.evaluate_dataset(
        test_loader, true_label=0, dataset_name="ì •ìƒ (Test)", device=DEVICE
    )
    
    # ë¹„ì •ìƒ ë°ì´í„° í‰ê°€
    abnormal_dataset = load_dataset_auto(ABNORMAL_HDF5_FILE, load_to_memory=LOAD_TO_MEMORY)
    abnormal_loader = DataLoader(abnormal_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, num_workers=0)
    abnormal_errors, abnormal_labels, abnormal_preds = evaluator.evaluate_dataset(
        abnormal_loader, true_label=1, dataset_name="ë¹„ì •ìƒ", device=DEVICE
    )
    
    # ì „ì²´ ê²°í•©
    all_errors = np.concatenate([normal_errors, abnormal_errors])
    all_labels = np.concatenate([normal_labels, abnormal_labels])
    all_preds = np.concatenate([normal_preds, abnormal_preds])
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = evaluator.calculate_medical_metrics(all_labels, all_preds, all_errors)
    
    # ê²°ê³¼ ì¶œë ¥ ë° ì‹œê°í™”
    print_performance_report(metrics)
    plot_medical_performance_dashboard(metrics, normal_errors, abnormal_errors,
                                       save_path=f'{OUTPUT_DIR}/medical_performance_dashboard_30s.png')
    
    print("\nâœ… í‰ê°€ ì™„ë£Œ!")
